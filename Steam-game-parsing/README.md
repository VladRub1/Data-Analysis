# Парсинг Steam

## Запуск парсера

Создаем проект с помощью `scrapy`:
```bash
python -m scrapy startproject steam
cd .\steam\
```

Запускаем парсер, собираем результат в `items.json`:
```bash
python -m scrapy crawl Steam -o items.json
```

### Содержание
* [examples](./examples) -- файл с примером результаты работы парсера 
(`items.json`)
* [steam](./steam) -- файл с кодом парсера
* [Python_2_HW_7.ipynb](./Python_2_HW_7.ipynb) -- файл с заданием и записью кода
через `%%writefile`

# Отчет об экспериментах

В начале я столкнулся с проблемой бесконечного скроллинга 
при поиске в Steam. По совету ассистента в чате, я выбрал следующий 
формат ссылки:
- `f'https://store.steampowered.com/search/?term={query}&ignore_preferences=1&page={page}'`
  - где `query` -- текст запроса
  - `ignore_preferences=1` -- игнорирование всех фильтров и рекомендаций
  - `page` -- номер страницы (обычно 25 игр на одной странице)

Дальше на примере одной ссылки на поисковый запрос и первой игры
в нем я в начале научился парсить все атрибуты с помощью 
`BeautifulSoup`. Затем я переписал парсинг большинства полей 
через `XPath` для удобства, но парсинг следующих полей оставил 
на `BeautifulSoup`, т.к. так было удобнее:
* ссылки на игры на результатах поиска
* ссылка на саму страницу, которую я паршу 
  * я добавил эту информацию, чтобы в результате можно было проверить, 
    откуда появились те или иные данные + отдебажить
  * эта информация (url своей страницы) лежит в тэге `meta`

Плюс в ходе работы я обнаружил интересную **фичу Яндекс Браузера**
(надеюсь, что это не читерство): при просмотре кода страницы
можно скопировать путь к тому или иному тэгу сразу в формате
**XPath**, нажав на `Копировать -> Копировать XPath`. Это очень 
помогло мне :)

Изначально я хотел делать парсер по архитектуре, которая была 
использована на семинаре с парсингом Aliexpress, а именно написать
следующие методы по отдельности:
* `start_requests`
* `parse_keyword_response`
* `parse_product_page`

Но при ее реализации я столкнулся с ошибками при переходе от 
страницы поиска к страницам конкретных игр из-за того, что
информация, которая лежит на этих разных уровнях, сложно мэтчилась
между собой, т.к. парсер работает асинхронно.

Плюс в ходе работы я отказался от идеи использовать **API scrapy**, 
поскольку понял, что 1) Steam никак не противодействует роботам 
для поиска (посмотрел в [robots.txt](https://store.steampowered.com/robots.txt))
и 2) при использовании API scrapy почему-то отличался код страницы,
который был, когда я парсил его вручную, ища нужные атрибуты --
из-за этого я получал ошибки и не хотел заново искать код для поиска
атрибутов в этом html-коде.

Поэтому я решил, как на лекции с парсингом Amazon, положить все
нужные ссылки на конкретные игры в `start_urls` парсера и пройтись
по ним с помощью метода `parse`.

После этого работа пошла эффективнее и проще, я довольно быстро
получил результат, немного поработав с ошибками фильтрации нужной
даты выпуска (оказывается, для нее может быть много непредсказуемых
значений: "Скоро выйдет", "Еще не объявлено" и т.д.). Для этого
добавил конструкцию try except в пайплайн.


### Источники:
* https://docs.scrapy.org/en/latest/intro/tutorial.html
* https://github.com/Palladain/Deep_Python_2023/blob/main/week11/Python_2_Lecture_11.ipynb
* https://github.com/Palladain/Deep_Python_2023/tree/main/week11/Aliexpress
* https://github.com/deouron/steam_parser (нашел в самом конце, когда 
фиксил баг с записью результатов)
